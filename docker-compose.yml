---
version: '2'

services:
  zookeeper:
    image: wurstmeister/zookeeper
    ports:
      - "2181:2181"

  kafka:
    hostname: kafka
    container_name: kafka
    image: wurstmeister/kafka
    ports:
      - "9092:9092"
    environment:
      # KAFKA_ADVERTISED_HOST_NAME: 192.168.1.6
      KAFKA_LISTENERS: INTERNAL://kafka:29092,EXTERNAL://kafka:9092
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:29092,EXTERNAL://192.168.1.101:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_CREATE_TOPICS: "runs:3:1,run_messages:1:1,run_statuses:1:1:compact,run_logs:1:1,run_files:1:1,dataset_storage_jobs:1:1,job_status:1:1:compact,transform_datasets:1:1,users:1:1,datasets:1:1"
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

  schema-registry:
    image: confluentinc/cp-schema-registry:5.4.1 
    container_name: schema-registry
    depends_on:
      - zookeeper
      - kafka
    ports:
      - 8081:8081
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      # SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: zookeeper:2181
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka:29092

  kafka-connect:
    image: confluentinc/cp-kafka-connect-base:5.4.1
    container_name: kafka-connect
    depends_on:
      - kafka
      - schema-registry
    ports:
      - 8083:8083
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "kafka:29092"
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: kafka-connect
      CONNECT_CONFIG_STORAGE_TOPIC: _kafka-connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: _kafka-connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: _kafka-connect-status
      CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_LOG4J_ROOT_LOGLEVEL: "INFO"
      CONNECT_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_PLUGIN_PATH: '/usr/share/java,/usr/share/confluent-hub-components/,/connectors/'
      # If you want to use the Confluent Hub installer to d/l component, but make them available
      # when running this offline, spin up the stack once and then run : 
      #   docker cp kafka-connect:/usr/share/confluent-hub-components ./connectors
      #   mv ./connectors/confluent-hub-components/* ./connectors
      #   rm -rf ./connectors/confluent-hub-components
    volumes:
      - $PWD/connectors:/connectors
    # In the command section, $ are replaced with $$ to avoid the error 'Invalid interpolation format for "command" option'
    command: 
      - bash 
      - -c 
      - |
        echo "Installing connector plugins"
        # confluent-hub install --no-prompt mdrogalis/voluble:0.2.0
        confluent-hub install --no-prompt confluentinc/kafka-connect-jdbc:5.4.1
        #
        # echo "Downloading JDBC driver"
        # cd /usr/share/confluent-hub-components/confluentinc-kafka-connect-jdbc
        # curl https://cdn.mysql.com/Downloads/Connector-J/mysql-connector-java-8.0.19.tar.gz | tar xz 
        #
        echo "Launching Kafka Connect worker"
        /etc/confluent/docker/run & 
        #
        echo "Installing connector transforms"
        confluent-hub install --no-prompt confluentinc/connect-transforms:1.3.2
        sleep infinity
  
  ksqldb-server:
    image: confluentinc/ksqldb-server:0.8.1
    hostname: ksqldb-server
    container_name: ksqldb-server
    depends_on:
      - kafka
      - kafka-connect
    ports:
      - "8088:8088"
    environment:
      KSQL_LISTENERS: http://0.0.0.0:8088
      KSQL_BOOTSTRAP_SERVERS: kafka:29092
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: "true"
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: "true"
      KSQL_KSQL_CONNECT_URL: http://kafka-connect:8083
      KSQL_KSQL_SCHEMA_REGISTRY_URL: http://schema-registry:8081

  ksqldb-cli:
    image: confluentinc/ksqldb-cli:0.8.1
    container_name: ksqldb-cli
    depends_on:
      - ksqldb-server
    entrypoint: /bin/sh
    tty: true

  postgres:
    image: postgres:13.1
    hostname: postgres-db
    container_name: postgres-db
    ports:
      - "5432:5432"
    environment:
      POSTGRES_MULTIPLE_DATABASES: "auth,users,projects,datasets,runs"
      POSTGRES_USER: "drboson"
      POSTGRES_PASSWORD: "darko"
    volumes:
      - ./volumes/postgres/data:/var/lib/postgresql/data
      - ./volumes/postgres/scripts:/docker-entrypoint-initdb.d

  pgadmin:
    image: dpage/pgadmin4:4.29
    hostname: pgadmin
    container_name: pgadmin
    ports:
      - "5050:80"
    environment:
      - PGADMIN_DEFAULT_EMAIL=darko@drboson.com
      - PGADMIN_DEFAULT_PASSWORD=darko
    volumes: 
      - ./volumes/pgadmin:/root/.pgadmin

        #  mongo:
        #    image: mongo:4.2.12
        #    hostname: mongodb
        #    container_name: mongodb
        #    ports:
        #      - "27017:27017"
        #    volumes:
        #      - ./volumes/mongo/data:/data/db 
        #      - ./volumes/mongo/scripts/init-mongo.sh:/docker-entrypoint-initdb.d/init-mongo.sh
        #    environment:
        #      MONGO_INITDB_ROOT_USERNAME: drboson
        #      MONGO_INITDB_ROOT_PASSWORD: darko
        #      MONGO_INITDB_DATABASE: datasets
        #
        #  mongo-express:
        #    image: mongo-express
        #    ports:
        #      - "8080:8081"
        #    environment:
        #      ME_CONFIG_MONGODB_ADMINUSERNAME: drboson
        #      ME_CONFIG_MONGODB_ADMINPASSWORD: darko
